I’m working on a static website for Coal Creek Guitars with a TypeScript build (tsc) that outputs JS to dist/. The site has multiple pages, including many guitar serial number decoder pages (one per brand) plus a general lookup page. There’s also a Listing Evaluator flow and a Guitars & Gear for Sale page.

CORE PAGES / FEATURES
- Homepage: links to major tools and a grid of brand decoder pages (Gibson, Fender, Kramer, etc.).
- Serial decoders: brand-specific pages under /decoders/ with JS logic in src/decoders/*. Main lookup uses src/main.ts.
- Guitars & Gear for Sale: page pulls inventory from Reverb via JS (src/listings.ts). It fetches https://api.reverb.com/api/my/listings and renders cards.
- Listing Evaluator: user submits listing URLs; results page shows scored listings; item detail page shows full AI summary and metadata.

LISTING EVALUATOR ARCHITECTURE (IMPORTANT)
Frontend pages:
- listing-evaluator.html (submit URLs)
- listing-evaluator-results.html (table of results)
- listing-evaluator-item.html (detail view)

Cloudflare Worker (workers/listing-evaluator/src/index.ts) powers the API:
- POST /api/listings/submit
  - Validates URLs, checks duplicates in D1, queues new ones.
  - If a duplicate exists and it’s archived, it un-archives it and does NOT rerun scraping.
- GET /api/listings
  - Returns D1 rows, filtered server-side: archived = false AND status != 'queued'.
  - Used by results page (paging supported).
- GET /api/listings/:id
  - Returns a single D1 record for detail page.
- POST /api/listings/:id/archive
  - Marks {archived: true} in D1.

BACKGROUND PROCESSING
- Worker calls Apify to scrape listing details (Facebook Marketplace + Craigslist).
- Apify webhook hits POST /api/listings/webhook, and the worker:
  - Fetches dataset items
  - Normalizes listing data (title, description, price, location, images)
  - Calls OpenAI to generate AI summary
  - Writes to D1 (status, title, price_asking, location, description, ai_summary, notes, photos, etc.)

D1
- Uses fields: url, source, status, title, price_asking, location, description, ai_summary, price_private_party, price_ideal, score, submitted_at.
- New fields added:
  - archived (checkbox)
  - photos (long text; URLs separated by newline)
- The worker now writes photos to D1 when updating a row (requires worker deploy).

FRONTEND BEHAVIORS
- Results page:
  - No “status” column anymore.
  - Client filters out queued items, but server also filters now.
- Item detail page:
  - Archive button disables on click and redirects back to results after success.
  - Shows a thumbnail if fields.photos has URLs (uses first URL).

BUILD / CACHE BUSTING
- scripts/update-cache-busters.mjs appends ?version=XXXXXX to CSS/JS in all HTML files (6-digit hash from file contents).
- npm run build runs tsc + cache buster.
- There’s also npm run cachebust.

OTHER NOTES
- The project is static HTML/CSS/JS served by Cloudflare, with Worker APIs under /api/listings/*.
- Reverb page now uses ?per_page=100 in the API call.
- SMS/notifications are not implemented yet, but Apify + Worker + D1 is already in place and could be extended.
